# -*- coding: utf-8 -*-
"""
@Time ： 2022/10/17 19:01
@Auth ： 异世の阿银
@File ：test.py
@IDE ：PyCharm
@Motto：ABC(Always Be Coding)
"""

'''
1.什么叫爬虫?
World Wide Web 万维网    中国最厉害的爬虫--百度

一个程序在万维网上自动获取数据的一个过程

万维网核心内容:
1.URL 唯一资源定位符
2.HTTP 超文本传输协议.定义数据交换的规范.
3.HTML 超文本标记语言.展示数据.

2.什么是Web?
Web指的就是Web系统,是以网站形式呈现出来的系统.
Web系统: 以网站形式呈现,通过浏览器访问,完成一定功能的系统.
服务端:①Python程序Flask框架②Java语言主要实现服务端
客户端:①浏览器②Python程序
遵循协议:HTTP - > 请求响应模型: 发送请求--返回响应
http协议规定了浏览器与服务器进行数据交换的全部规则.

3.什么是Web框架?
Web框架是一个建设web应用的半成品,这个半成品完成了HTTP协议的通信规则.
完成了什么?需要我们做什么?
服务端flask框架 : ①实现了HTTP协议的服务端的半成品程序.②没有完成业务逻辑的处理. 1.路由@route + 2.逻辑处理


4.什么是HTTP?
客户端发送请求给服务端,必须写一个'url唯一资源定位符路径' (请求路径)
协议://公司的域名(IP地址):端口号/资源名称
https://www.baidu.com:443/index.html

域名 - > IP
www.baidu.com - > 202.108.22.5
映射关系是网络上的'域名服务器'自动完成的  全世界9台,中国1台

端口号:
80: http协议中服务端默认的端口 
443 https协议中服务端默认的端口
s: secure
自定义程序一般都是1024以上的端口号.
因为1024以下的端口号都是给一些知名的应用程序预留的.
不提供服务的程序,可以不指定端口,需要时由系统分配未占用的端口.
mysql数据库服务: 3306
mongoDB数据库服务: 27017
端口号范围: 0~65535  两个字节的最大值2 ** 16
端口号是用来区分同一台 服务器/电脑 中不同的应用程序.

HTTP: Hyper Text Transfer Protocol 超文本传输协议
HTTPS: Hypertext Transfer Protocol Secure 超文本传输安全协议 公钥+私钥

index.html: 网站的首页地址

本地回环地址:localhost<-->127.0.0.1
特殊: 不是去互联网找计算机,这个地址到本电脑的网卡后,直接就回来了.
凡是192.168.134.1开头的地址都是局域网地址

PID 进程编号

5.什么是HTML?
HTML 超文本标记语言.作用就是用来展示数据.数据一般都是在浏览器上展示的.
网站- 右键- 检查
预定义标签
I know html.(I know how to meet ladies.)

6.爬虫的基本流程是怎样的?
客户端程序,可以自动的去互联网找数据,最后将需要的数据存储.
①发送请求: 通过http库向目标站点发送请求,即发送一个request,请求可以包含额外的headers等信息.等待服务响应.
②获取响应内容: 如果服务器能够正常响应,会得到一个response,response对象的内容就包含了我们请求中获取页面的内容,类型可以有
HTML,JSON字符串,文本数据,二进制数据(图片,音频,视频...)等类型.
③解析内容: 大部分内容都是HTML标签数据.网页解析,解析有很多种方式.BeautifulSoup.Xpath
④保存数据: 保存数据也有很多种方式,可以保存到数据库,文本文件中.如果是二进制数据,图片就保存为图片格式,视频就保存为视频格式.

7.爬虫程序能抓取怎样的数据及保存的方式
①网页文本数据: 如html,文档,json数据,文本数据...
②图片: 获取的就是二进制数据,保存为图片格式即可.
③视频: 二进制数据,保存为视频格式即可.
④其他: 只要是能够请求到的数据,都可以获取并保存.


8.解析数据的方式有哪些?
①直接处理
②json解析
③正则表达式解析
④BeautifulSoup第三方解析库 (数据的文档树结构)
⑤Xpath,CSS

9.为什么我抓到的数据和浏览器看到的数据不一样?
解决方式:浏览器-网络
selenium 自动化解析,打开浏览器,模拟浏览器的行为.

10.怎样解决JavaScript渲染的问题?
①分析ajax请求
②selenium/webdriver 网页驱动器模拟浏览器的执行过程.

12.网络爬虫引起的问题
①网络爬虫的'性能骚扰'    自动化程序 1s 100万次请求,占用大量资源
②网络爬虫的法律风险
③网络爬虫的隐私泄露
④网络爬虫的限制:
来源审查: 判断User-Agent进行限制
检查来访HTTP协议头的User-Agent域,只响应浏览器或友好爬虫的访问.
发布公告: Robots协议
告知所有爬虫网站的爬取策略,要求爬虫遵守.


13.Robots协议
Robots Exclusion Standard, 网络爬虫排除标准
作用: 网站告知网络爬虫哪些页面可以抓取,哪些不行.
形式: 在网站根目录下的robots.txt文件
www.baidu.com/robots.txt
www.sina.com.cn/robots.txt

对Robots协议的理解:
访问量很小: 可以遵守     非商业偶尔: 建议遵守
访问量很大: 建议遵守     商业利益: 必须遵守
爬取全网: 必须遵守
原则: 类似于人类的爬虫程序可以不参考Robots协议

15.Web前端开发概述
Web系统: 以网站形式呈现,通过浏览器访问,完成一定功能的系统.
前端: 网页上为用户呈现的部分.
后端: 与数据库进行交互,完成数据传递与存储.

16.网站与网页
网站: web site 网页的集合  文件夹
网页: web page 网站中的一页  文件
主页: homepage 进入网站看到的第一个页面,主页的文件名通常都是index.html
浏览器: 解析网页源代码,渲染网页

17. Web前端开发技术
①HTML: 页面的结构 标记语言
②CSS: 美化页面
③JavaScript: 行为交互

18.HTML概述
前端技术标准: W3C 万维网联盟(World Wide Web) 
https://www.w3school.com.cn
programming 编程模块

19.HTML标签
<title></title>
<img/>
HTML DOM树
DOM: Document Object Model(文档对象模型)


'''

# 第一步: 学习HTML语言
# 第二步: 学习flask框架, 编写服务端程序
# 第三步: 学习Python中的urllib.request请求库, 实现客户端的编写(模拟浏览器的数据获取)
# 第四步: 学习MySQL数据库, 将获取的数据存储到数据库中.
